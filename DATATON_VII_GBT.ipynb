{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENTRENAMIENTO - GRADIENT BOOSTING TREES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del presente notebook consiste en entrenar un modelo de Gradient Boosting Trees para aplicarlo a los datos de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in c:\\users\\sobando\\anaconda3\\lib\\site-packages (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar Pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.appName(\"model\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARGAR DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path definition\n",
    "path = \"output/preprocessing/preprocessing_data.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataframe\n",
    "df = spark.read.parquet(path, header= True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10660715"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify rows\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input and drop variables\n",
    "input_values = df.columns\n",
    "drop_values = ['periodo','id_cli','fecha_nacimiento','ult_actual','gasto_familiar','genero_dummy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean input variables\n",
    "input_features = [x for x in input_values if x not in drop_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null\n",
    "train = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281666"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set testing path\n",
    "path = \"output/preprocessing/preprocessing_data_test.parquet\"\n",
    "# Read dataframe\n",
    "df_2 = spark.read.parquet(path, header= True, inferSchema=True)\n",
    "# Replace null\n",
    "test = df_2.fillna(0)\n",
    "# Verify rows\n",
    "df_2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELADO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizar - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize variables to define the features column\n",
    "feat_vector = VectorAssembler(inputCols=input_features, outputCol= \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appply vectorization to train\n",
    "transTrain = feat_vector.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variables for the train model\n",
    "train_model = transTrain.select(\"id_cli\",\"periodo\",\"features\",\"gasto_familiar\")\n",
    "train_model = train_model.fillna(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appply vectorization to test\n",
    "transTest = feat_vector.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variables for the test model\n",
    "test_model = transTest.select(\"id_cli\",\"periodo\",\"features\")\n",
    "test_model = test_model.fillna(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "| id_cli|periodo|            features|\n",
      "+-------+-------+--------------------+\n",
      "|2311966| 202001|(210,[0,1,2,7,8,9...|\n",
      "|3161308| 202003|(210,[0,1,2,9,10,...|\n",
      "|3175733| 202003|(210,[0,1,2,7,8,9...|\n",
      "|3180301| 202003|(210,[0,1,2,9,10,...|\n",
      "|3189113| 202004|(210,[0,1,2,9,10,...|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply statistical learning\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'gasto_familiar', maxIter=10)\n",
    "gbt_model = gbt.fit(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predictions = gbt_model.transform(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281666"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "|   id_registro|    gasto_familiar|\n",
      "+--------------+------------------+\n",
      "|2311966#202001| 595871.1489608595|\n",
      "|3161308#202003| 558908.0614379189|\n",
      "|3175733#202003|1087309.9321845034|\n",
      "|3180301#202003| 475973.2770270521|\n",
      "|3189113#202004|1253690.1152068963|\n",
      "|3200186#202004|1099354.6912965178|\n",
      "|8135607#202009| 1289468.422120331|\n",
      "|4891981#202007| 1073536.923961848|\n",
      "|4264978#202007| 554154.5817756066|\n",
      "|3848030#202005|  470194.388444068|\n",
      "|3849659#202005|409231.67288724787|\n",
      "|8150594#202009| 498916.0703908676|\n",
      "|8163742#202009|  888659.557870885|\n",
      "|8172268#202009| 411837.8782343126|\n",
      "|8174312#202009|2118319.0940481625|\n",
      "|4319165#202007| 581229.7657017352|\n",
      "|4344726#202007| 506063.4926351437|\n",
      "|4363030#202007|395401.16342389246|\n",
      "|8175960#202009| 2697446.742138687|\n",
      "|8177985#202009|1174634.4508090934|\n",
      "+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show prediction\n",
    "df_final = predictions.select(concat(str(\"id_cli\"),lit('#'),str(\"periodo\")).alias(\"id_registro\"),col(\"prediction\").alias(\"gasto_familiar\"))\n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.toPandas().to_csv(\"output/implementations/df_final_20200128.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
