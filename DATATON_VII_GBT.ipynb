{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENTRENAMIENTO - LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del presente notebook consiste en entrenar un modelo de regression multiple para aplicarlo a los datos de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in c:\\users\\sobando\\anaconda3\\lib\\site-packages (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar Pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.appName(\"model\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARGAR DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path definition\n",
    "path = \"output/preprocessing/preprocessing_data.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataframe\n",
    "df = spark.read.parquet(path, header= True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10660715"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify rows\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input and drop variables\n",
    "input_values = df.columns\n",
    "drop_values = ['periodo','id_cli','fecha_nacimiento','ult_actual','gasto_familiar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean input variables\n",
    "input_features = [x for x in input_values if x not in drop_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null\n",
    "train = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281666"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set testing path\n",
    "path = \"output/preprocessing/preprocessing_data_test.parquet\"\n",
    "# Read dataframe\n",
    "df_2 = spark.read.parquet(path, header= True, inferSchema=True)\n",
    "# Replace null\n",
    "test = df_2.fillna(0)\n",
    "# Verify rows\n",
    "df_2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELADO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizar - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize variables to define the features column\n",
    "feat_vector = VectorAssembler(inputCols=input_features, outputCol= \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appply vectorization to train\n",
    "transTrain = feat_vector.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variables for the train model\n",
    "train_model = transTrain.select(\"id_cli\",\"periodo\",\"features\",\"gasto_familiar\")\n",
    "train_model = train_model.fillna(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3198308"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count rows\n",
    "predictions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appply vectorization to test\n",
    "transTest = feat_vector.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variables for the test model\n",
    "test_model = transTest.select(\"id_cli\",\"periodo\",\"features\")\n",
    "test_model = test_model.fillna(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "| id_cli|periodo|            features|\n",
      "+-------+-------+--------------------+\n",
      "|2311966| 202001|(211,[0,1,2,7,8,9...|\n",
      "|3161308| 202003|(211,[0,1,2,9,10,...|\n",
      "|3175733| 202003|(211,[0,1,2,7,8,9...|\n",
      "|3180301| 202003|(211,[0,1,2,9,10,...|\n",
      "|3189113| 202004|(211,[0,1,2,9,10,...|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply statistical learning\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'gasto_familiar', maxIter=10)\n",
    "gbt_model = gbt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predictions = gbt_model.transform(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|id_registro|    gasto_familiar|\n",
      "+-----------+------------------+\n",
      "|  17#201903| 557001.8999391494|\n",
      "|  17#201910|  777464.283014857|\n",
      "|  17#201911| 795243.0997271333|\n",
      "|  17#202004| 864202.9904496818|\n",
      "|  17#202008| 802104.4736187836|\n",
      "|  17#202009| 728024.7795735411|\n",
      "| 213#201904| 522370.7110925317|\n",
      "| 213#201905| 522370.7110925317|\n",
      "| 213#201911| 593066.3217000682|\n",
      "| 213#202001| 617089.4188316514|\n",
      "| 213#202004| 625418.5439857439|\n",
      "| 213#202005|   559115.04601236|\n",
      "| 213#202008| 550272.6431850082|\n",
      "| 274#202009| 860235.3384508649|\n",
      "| 332#201907| 812542.9226471953|\n",
      "| 332#201910| 847538.4959882563|\n",
      "| 332#201911| 831575.1416064955|\n",
      "| 332#202010|  871165.690379369|\n",
      "| 345#201904| 614038.1129008438|\n",
      "| 400#201905|372798.63809345086|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show prediction\n",
    "df_final = predictions.select(concat(str(\"id_cli\"),lit('#'),str(\"periodo\")).alias(\"id_registro\"),col(\"prediction\").alias(\"gasto_familiar\"))\n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3198308"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.toPandas().to_csv(\"../output/implementations/df_final_20200128.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
