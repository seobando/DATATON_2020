{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENTRENAMIENTO - RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del presente notebook consiste en entrenar un modelo de Random Forest para aplicarlo a los datos de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in c:\\users\\sobando\\anaconda3\\lib\\site-packages (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar Pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.appName(\"model\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARGAR DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path definition\n",
    "path = \"output/preprocessing/preprocessing_data.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataframe\n",
    "train = spark.read.parquet(path, header= True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9670308"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify rows\n",
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast binary variables\n",
    "train = (train\n",
    "         .withColumn(\"ind_mora_vigente\",col(\"ind_mora_vigente\").cast(\"integer\"))\n",
    "         .withColumn(\"cartera_castigada\",col(\"cartera_castigada\").cast(\"integer\"))\n",
    "         .withColumn(\"tenencia_tc\",col(\"tenencia_tc\").cast(\"integer\"))\n",
    "         .withColumn(\"tiene_consumo\",col(\"tiene_consumo\").cast(\"integer\"))\n",
    "         .withColumn(\"tiene_crediagil\",col(\"tiene_crediagil\").cast(\"integer\"))\n",
    "         .withColumn(\"tiene_ctas_activas\",col(\"tiene_ctas_activas\").cast(\"integer\"))\n",
    "         .withColumn(\"tiene_ctas_embargadas\",col(\"tiene_ctas_embargadas\").cast(\"integer\"))\n",
    "         .withColumn(\"tiene_cred_hipo_1\",col(\"tiene_cred_hipo_1\").cast(\"integer\"))\n",
    "         .withColumn(\"tiene_cred_hipo_2\",col(\"tiene_cred_hipo_2\").cast(\"integer\"))\n",
    "         .withColumn(\"pension_fopep\",col(\"pension_fopep\").cast(\"integer\"))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input and drop variables\n",
    "input_values = train.columns\n",
    "drop_values = ['periodo','id_cli','fecha_nacimiento','ult_actual','gasto_familiar','genero_dummy','codigo_ciiu','NI','rep_calif_cred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean input variables\n",
    "input_features = [x for x in input_values if x not in drop_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281666"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set testing path\n",
    "path = \"output/preprocessing/preprocessing_data_test.parquet\"\n",
    "# Read dataframe\n",
    "test = spark.read.parquet(path, header= True, inferSchema=True)\n",
    "# Verify rows\n",
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (test\n",
    "         .withColumn(\"ind_mora_vigente\",col(\"ind_mora_vigente\").cast(\"integer\"))\n",
    "         .withColumn(\"cartera_castigada\",col(\"cartera_castigada\").cast(\"integer\"))\n",
    "         .withColumn(\"tenencia_tc\",col(\"tenencia_tc\").cast(\"integer\"))\n",
    "         .withColumn(\"tiene_consumo\",col(\"tiene_consumo\").cast(\"integer\"))\n",
    "         .withColumn(\"tiene_crediagil\",col(\"tiene_crediagil\").cast(\"integer\"))\n",
    "         .withColumn(\"tiene_ctas_activas\",col(\"tiene_ctas_activas\").cast(\"integer\"))\n",
    "         .withColumn(\"tiene_ctas_embargadas\",col(\"tiene_ctas_embargadas\").cast(\"integer\"))\n",
    "         .withColumn(\"tiene_cred_hipo_1\",col(\"tiene_cred_hipo_1\").cast(\"integer\"))\n",
    "         .withColumn(\"tiene_cred_hipo_2\",col(\"tiene_cred_hipo_2\").cast(\"integer\"))\n",
    "         .withColumn(\"pension_fopep\",col(\"pension_fopep\").cast(\"integer\"))\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELADO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizar - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize variables to define the features column\n",
    "feat_vector = VectorAssembler(inputCols=input_features, outputCol= \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appply vectorization to train\n",
    "transTrain = feat_vector.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variables for the train model\n",
    "train_model = transTrain.select(\"id_cli\",\"periodo\",\"features\",\"gasto_familiar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appply vectorization to test\n",
    "transTest = feat_vector.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variables for the test model\n",
    "test_model = transTest.select(\"id_cli\",\"periodo\",\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "| id_cli|periodo|            features|\n",
      "+-------+-------+--------------------+\n",
      "|1165927| 201908|(62,[0,1,3,4,8,12...|\n",
      "|1172919| 201908|(62,[0,1,2,4,17,1...|\n",
      "|1538512| 201909|(62,[0,1,2,3,4,17...|\n",
      "|3371270| 202004|(62,[0,1,2,4,5,8,...|\n",
      "|2784853| 202003|(62,[0,1,2,4,12,1...|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homologate target variable to label\n",
    "trainingData = train_model.withColumnRenamed(\"gasto_familiar\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homologate target variable to label\n",
    "testData = test_model.withColumnRenamed(\"gasto_familiar\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-regression\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a RandomForest model.\n",
    "rf = RandomForestRegressor(featuresCol=\"indexedFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexer and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select example rows to display.\n",
    "predictions = predictions.withColumnRenamed(\"label\",\"gasto_familiar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281666"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "|   id_registro|    gasto_familiar|\n",
      "+--------------+------------------+\n",
      "|1165927#201908|2245627.2577155763|\n",
      "|1172919#201908| 928273.0586991375|\n",
      "|1538512#201909| 519093.5845291334|\n",
      "|3371270#202004| 518277.5145250812|\n",
      "|2784853#202003| 589125.6672007655|\n",
      "|2219310#202001| 546253.2360973016|\n",
      "|2220638#202001| 586685.4051289329|\n",
      "|1568926#201909| 646398.5598656738|\n",
      "|1573039#201909| 709633.2268067767|\n",
      "|2430420#202002| 991626.9503412399|\n",
      "|1455662#201909| 857854.5563419787|\n",
      "|1461386#201909|1081357.2737375868|\n",
      "|1463134#201909| 815969.0614879329|\n",
      "|1477680#201909| 512339.2879311177|\n",
      "|1361632#201909|  1465039.83426048|\n",
      "|1362813#201909| 641757.9560151295|\n",
      "|1379397#201909|1393013.6347733508|\n",
      "| 834901#201905| 593604.9020455598|\n",
      "| 839363#201905| 1507261.971837223|\n",
      "| 842749#201905|1733074.7318330582|\n",
      "+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show prediction\n",
    "df_final = predictions.select(concat(str(\"id_cli\"),lit('#'),str(\"periodo\")).alias(\"id_registro\"),col(\"prediction\").alias(\"gasto_familiar\"))\n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.toPandas().to_csv(\"output/implementations/model_RF_20200129.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
